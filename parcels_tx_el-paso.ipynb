{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597239218739",
   "display_name": "Python 3.8.2 64-bit ('cdr': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El Paso Exploration Notebook\n",
    "\n",
    "## Steps:\n",
    "\n",
    "1. Add any required modules to the imports\n",
    "2. Set County specific variables\n",
    "3. Set path to sample dataset(s)\n",
    "4. Import the dataset(s) in the order that they will be merged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import datetime\n",
    "import json\n",
    "import pyspark\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, DoubleType, IntegerType, DateType, TimestampType, BooleanType\n",
    "import quinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set county vars\n",
    "county = \"el-paso\"\n",
    "state = \"TX\"\n",
    "fips_code = \"48141\"\n",
    "\n",
    "schema_check_db = \"faxdb\"\n",
    "schema_check_coll = \"parcels_validation_test\"\n",
    "\n",
    "county_vars = {\n",
    "    \"county\": county,\n",
    "    \"state\": state,\n",
    "    \"fips_code\": fips_code,\n",
    "    \"pipeline_run_id\": \"987654321\",\n",
    "    \"pipeline_run_time\": datetime.datetime.now(),\n",
    "    \"dataset_date\": datetime.datetime.now(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init spark with delta, mongo support and 16g of memory\n",
    "spark = (pyspark.sql.SparkSession.builder.appName(county)\n",
    "        .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:0.7.0\")\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "        .config(\n",
    "            \"spark.sql.catalog.spark_catalog\",\n",
    "            \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "        )\n",
    "        .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\")\n",
    "        .config(\"spark.mongodb.input.uri\", f\"mongodb://127.0.0.1/{county}.default\")\n",
    "        .config(\"spark.mongodb.output.uri\", f\"mongodb://127.0.0.1/{county}.default\")\n",
    "        .config(\"spark.driver.memory\", \"16g\")\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample dataset paths (version controlled)\n",
    "sample_ade_info = \"./samples/2020-08-03_002061_APPRAISAL_INFO.TXT\"\n",
    "sample_ade_land = \"./samples/2020-08-03_002061_APPRAISAL_LAND_DETAIL.TXT\"\n",
    "sample_ade_imp_info = \"./samples/2020-08-03_002061_APPRAISAL_IMPROVEMENT_DETAIL.TXT\"\n",
    "# full datasets paths (not version controlled)\n",
    "full_ade_info = \"\"\n",
    "full_ade_land = \"\"\n",
    "full_ade_imp_info = \"\"\n",
    "# set dataset paths\n",
    "path_ade_info = sample_ade_info\n",
    "path_ade_land = sample_ade_land\n",
    "path_ade_imp_info = sample_ade_imp_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load schema path\n",
    "schema_path = f\"./schema_tx_{county}.json\"\n",
    "with open(schema_path, \"rb\") as s:\n",
    "    schema = StructType.fromJson(json.load(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset APPRAISAL_INFO.TXT\n",
    "def _transform_ade_info():\n",
    "    return (\n",
    "        (spark.read.text(path_ade_info)\n",
    "                .select(\n",
    "                    F.trim(F.col(\"value\").substr(1, 12)).cast(\"string\").alias(\"parcel_id\"),\n",
    "                    F.trim(F.col(\"value\").substr(547,50)).cast(\"string\").alias(\"tax_id\"),\n",
    "                    F.trim(F.col(\"value\").substr(13, 5)).alias(\"type\"),\n",
    "                    F.trim(F.col(\"value\").substr(4460,15)).alias(\"street_number\"),\n",
    "                    F.trim(F.col(\"value\").substr(1040,10)).alias(\"street_pre_direction\"),\n",
    "                    F.trim(F.col(\"value\").substr(1050,50)).alias(\"street_name\"),\n",
    "                    F.trim(F.col(\"value\").substr(1100,10)).alias(\"street_post_direction\"),\n",
    "                    F.trim(F.col(\"value\").substr(4475,5)).alias(\"unit\"),\n",
    "                    F.trim(F.col(\"value\").substr(1110,30)).alias(\"city\"),\n",
    "                    F.trim(F.col(\"value\").substr(1140,10)).alias(\"zip\"),\n",
    "                    F.trim(F.col(\"value\").substr(1150,255)).alias(\"legal_description\"),\n",
    "                    F.trim(F.col(\"value\").substr(1686,10)).alias(\"legal_subdivision\"),\n",
    "                    F.trim(F.col(\"value\").substr(2734,10)).alias(\"improvement_use_code\"),\n",
    "                    F.trim(F.col(\"value\").substr(2742,10)).alias(\"land_use_code\"),\n",
    "                    (F.trim(F.col(\"value\").substr(2772,20)).cast(\"double\") / 10000).alias(\"lot_size_acres\"),\n",
    "                    F.trim(F.col(\"value\").substr(4214,14)).cast(\"integer\").alias(\"market_value\"),\n",
    "                    F.trim(F.col(\"value\").substr(1946,15)).cast(\"integer\").alias(\"assessed_value\"),\n",
    "                    F.to_date(F.trim(F.col(\"value\").substr(2034,25)), \"MMddyyyy\").alias(\"deed_transfer_date\"),\n",
    "                    F.trim(F.col(\"value\").substr(4492,70)).alias(\"oor_1\"),\n",
    "                    F.trim(F.col(\"value\").substr(4562,60)).alias(\"oor_2\"),\n",
    "                    F.trim(F.col(\"value\").substr(4622,60)).alias(\"oor_3\"),\n",
    "                    F.trim(F.col(\"value\").substr(4682,60)).alias(\"oor_4\"),\n",
    "                    F.trim(F.col(\"value\").substr(4742,50)).alias(\"oor_5\"),\n",
    "                    F.trim(F.col(\"value\").substr(4792,50)).alias(\"oor_6\"),\n",
    "                    F.trim(F.col(\"value\").substr(4847,5)).alias(\"oor_7\"),\n",
    "                    F.trim(F.col(\"value\").substr(4852,4)).alias(\"oor_8\"),\n",
    "                    F.trim(F.col(\"value\").substr(4842,5)).alias(\"oor_9\")         \n",
    "                )\n",
    "                .where((F.col(\"type\") == \"R\") | (F.col(\"type\") == \"M\"))\n",
    "                .withColumn(\n",
    "                    \"parcel_id\",\n",
    "                    F.regexp_replace('parcel_id', r'^[0]*', '')\n",
    "                )\n",
    "                .withColumn(\n",
    "                    \"legal_description\",\n",
    "                    quinn.single_space(F.col(\"legal_description\"))\n",
    "                )\n",
    "                .withColumn(\n",
    "                    \"street_address\",\n",
    "                    quinn.single_space(\n",
    "                        F.regexp_replace(\n",
    "                            F.concat_ws(\n",
    "                                \" \",\n",
    "                                \"street_number\",\n",
    "                                \"street_pre_direction\",\n",
    "                                \"street_name\",\n",
    "                                \"street_post_direction\",\n",
    "                                \"unit\",\n",
    "                            ),\n",
    "                            '\"',\n",
    "                            \"\",  # regexp replacement values\n",
    "                        )\n",
    "                    ),\n",
    "                )\n",
    "                .withColumn(\n",
    "                    \"oor\",\n",
    "                    quinn.single_space(\n",
    "                        F.regexp_replace(\n",
    "                            F.concat_ws(\n",
    "                                \" \",\n",
    "                                \"oor_1\",\n",
    "                                \"oor_2\",\n",
    "                                \"oor_3\",\n",
    "                                \"oor_4\",\n",
    "                                \"oor_5\",\n",
    "                                \"oor_6\",\n",
    "                                \"oor_7\",\n",
    "                                \"oor_9\",\n",
    "                            ),\n",
    "                            '\"',\n",
    "                            \"\",  # regexp replacement values\n",
    "                        )\n",
    "                    ),\n",
    "                )\n",
    "        ).drop(\"oor_1\", \"oor_2\", \"oor_3\", \"oor_4\", \"oor_5\", \"oor_6\", \"oor_7\", \"oor_8\", \"oor_9\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ade_info = _transform_ade_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load APPRAISAL_INFO.TXT to db\n",
    "df_ade_info.write.format(\"mongo\").mode(\"overwrite\").option(\"collection\", \"df_ade_info\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read APPRAISAL_LAND_DETAIL.TXT\n",
    "def _transform_land():\n",
    "    w_land = Window.partitionBy(\"parcel_id\")\n",
    "    return (\n",
    "        (spark.read.text(path_ade_land)\n",
    "            .select(\n",
    "                F.trim(F.col(\"value\").substr(1, 12)).cast(\"string\").alias(\"parcel_id\"),\n",
    "                #   Incorrect values, see readme\n",
    "                F.trim(F.col(\"value\").substr(39,25)).cast(\"string\").alias(\"land_desc_desc\"),\n",
    "                F.trim(F.col(\"value\").substr(84,14)).cast(\"integer\").alias(\"sqft\"),\n",
    "                F.trim(F.col(\"value\").substr(112,14)).cast(\"integer\").alias(\"lot_depth\"),\n",
    "                F.trim(F.col(\"value\").substr(98,14)).cast(\"integer\").alias(\"lot_frontage\")\n",
    "            )\n",
    "            .withColumn(\n",
    "                \"parcel_id\",\n",
    "                F.regexp_replace('parcel_id', r'^[0]*', '')\n",
    "            )\n",
    "            .withColumn(\"lot_size_sqft\", F.sum(\"sqft\").over(w_land))\n",
    "            .withColumn(\"lot_depth_ft\", F.sum(\"lot_depth\").over(w_land))\n",
    "            .withColumn(\"lot_frontage_ft\", F.sum(\"lot_frontage\").over(w_land))\n",
    "        ).drop_duplicates([\"parcel_id\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ade_land = _transform_land()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load APPRAISAL_LAND_DETAIL.TXT to db\n",
    "df_ade_land.write.format(\"mongo\").mode(\"overwrite\").option(\"collection\", \"df_ade_land\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read APPRAISAL_IMPROVEMENT_DETAIL.TXT\n",
    "def _transfrom_imp_detail():\n",
    "    w_impr = Window.partitionBy(\"parcel_id\")\n",
    "    return(\n",
    "    \n",
    "        (spark.read.text(path_ade_imp_info)\n",
    "            .select(\n",
    "                F.trim(F.col(\"value\").substr(1,12)).alias(\"parcel_id\"),\n",
    "                F.trim(F.col(\"value\").substr(86,4)).cast(\"integer\").alias(\"year\"),\n",
    "                F.trim(F.col(\"value\").substr(94,15)).cast(\"integer\").alias(\"sqft\"),\n",
    "                F.trim(F.col(\"value\").substr(41,10)).alias(\"imprv_det_type_cd\"),\n",
    "            ).filter(\"imprv_det_type_cd like 'MA%'\")\n",
    "            .withColumn(\n",
    "                    \"parcel_id\",\n",
    "                    F.regexp_replace('parcel_id', r'^[0]*', '')\n",
    "            )\n",
    "            .withColumn(\"structure_total_sqft\", F.sum(\"sqft\").over(w_impr))\n",
    "            .withColumn(\"year_built\", F.min(\"year\").over(w_impr))\n",
    "        ).drop(\"sqft\", \"year\").drop_duplicates([\"parcel_id\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+---------+-----------------+--------------------+----------+\n|parcel_id|imprv_det_type_cd|structure_total_sqft|year_built|\n+---------+-----------------+--------------------+----------+\n|100010   |MA               |7472                |2014      |\n|100735   |MA               |1252                |1961      |\n|100768   |MA               |1286                |2004      |\n|10096    |MA               |2048                |1994      |\n|100964   |MA               |678                 |1987      |\n|101021   |MA               |973                 |1916      |\n|101122   |MA               |2468                |2006      |\n|101205   |MA               |1348                |2007      |\n|101261   |MA               |672                 |1981      |\n|101272   |MA               |806                 |1952      |\n|102113   |MA               |2066                |1975      |\n|102539   |MA               |2339                |1987      |\n|102684   |MA               |1595                |2007      |\n|102745   |MA               |1188                |1977      |\n|102944   |MA               |2576                |1952      |\n|103050   |MA               |475                 |1993      |\n|103432   |MA               |653                 |2005      |\n|10351    |MA               |1029                |1983      |\n|103634   |MA               |1406                |1956      |\n|104344   |MA               |56                  |2001      |\n+---------+-----------------+--------------------+----------+\nonly showing top 20 rows\n\n"
    }
   ],
   "source": [
    "df_ade_imp_info = _transfrom_imp_detail().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+---------+-----------------+--------------------+----------+\n|parcel_id|imprv_det_type_cd|structure_total_sqft|year_built|\n+---------+-----------------+--------------------+----------+\n|100010   |MA               |7472                |2014      |\n+---------+-----------------+--------------------+----------+\n\n"
    }
   ],
   "source": [
    "df_ade_imp_info.where(\"parcel_id = 100010\").orderBy(\"imprv_det_type_cd\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load APPRAISAL_IMPROVEMENT_DETAIL.TXT to db\n",
    "df_ade_imp_info.write.format(\"mongo\").mode(\"overwrite\").option(\"collection\", \"df_ade_imp_info\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge datasets (if necassary)\n",
    "\n",
    "# Example assuming more than one dataset\n",
    "df_county = df_ade_info.join(df_ade_land, \"parcel_id\", \"left\").join(df_ade_imp_info, \"parcel_id\", \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add required columns\n",
    "county_parcels = df_county \\\n",
    "    .withColumn(\"county\", F.lit(county_vars[\"county\"])) \\\n",
    "        .withColumn(\n",
    "        \"fingerprint\", F.base64(F.concat(F.lit(county_vars[\"county\"]), \"parcel_id\"))\n",
    "        ) \\\n",
    "        .withColumn(\"state\", F.lit(county_vars[\"state\"])) \\\n",
    "        .withColumn(\"fips_code\", F.lit(county_vars[\"fips_code\"])) \\\n",
    "        .withColumn(\"pipeline_run_id\", F.lit(county_vars[\"pipeline_run_id\"])) \\\n",
    "        .withColumn(\"pipeline_run_time\", F.lit(county_vars[\"pipeline_run_time\"])) \\\n",
    "        .withColumn(\"dataset_date\", F.lit(county_vars[\"dataset_date\"])) \\\n",
    "        .withColumn(\"record_hash\", F.sha2(F.concat_ws(\"||\", *df_county.columns), 256)) \\\n",
    "    .drop_duplicates([\"fingerprint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load final dataset into a mongo collection with schema validation\n",
    "county_parcels.write.format(\"mongo\").mode(\"append\").option(\"database\", schema_check_db).option(\"collection\", schema_check_coll).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get missing fields and document why they're missing on county readme.md\n",
    "missing_fields = [f for f in schema.fieldNames() if f not in county_parcels.schema.fieldNames()]\n",
    "print(missing_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for extra fields\n",
    "extra_fields = [f for f in county_parcels.schema.fieldNames() if f not in schema.fieldNames()]\n",
    "print(extra_fields)"
   ]
  }
 ]
}